{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/auroraleport/Documents/LePort_git/Springboard_2016/Kick_Cap_2016'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/auroraleport/Documents/Kickstarter_2016-07-15/Kickstarter.csv\n",
      "1\n",
      "/Users/auroraleport/Documents/Kickstarter_2016-07-15/Kickstarter001.csv\n",
      "2\n",
      "/Users/auroraleport/Documents/Kickstarter_2016-07-15/Kickstarter002.csv\n",
      "3\n",
      "/Users/auroraleport/Documents/Kickstarter_2016-07-15/Kickstarter003.csv\n",
      "4\n",
      "/Users/auroraleport/Documents/Kickstarter_2016-07-15/Kickstarter004.csv\n",
      "5\n",
      "/Users/auroraleport/Documents/Kickstarter_2016-07-15/Kickstarter005.csv\n",
      "6\n",
      "/Users/auroraleport/Documents/Kickstarter_2016-07-15/Kickstarter006.csv\n",
      "7\n",
      "/Users/auroraleport/Documents/Kickstarter_2016-07-15/Kickstarter007.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "appended_data = []\n",
    "for infile in glob.glob('/Users/auroraleport/Documents/Kickstarter_2016-07-15/*.csv'):\n",
    "    print infile\n",
    "    data = pd.read_csv(infile)\n",
    "    data['filename'] = infile\n",
    "    #print data\n",
    "    appended_data.append(data) ## store dataframes in list\n",
    "    print len(appended_data)\n",
    "appended_data = pd.concat(appended_data, axis=0) ## see documentation for more info\n",
    "#pd.DataFrame(appended_data)\n",
    "#appended_data.to_csv('appedned.csv')\n",
    "len(appended_data)\n",
    "appended_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_data = appended_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extracting targeted values:\n",
    "print k_data.columns.values\n",
    "k_var = k_data[['category','name','blurb','currency','static_usd_rate','goal','backers_count','state','launched_at','state_changed_at']]\n",
    "print len(k_var)\n",
    "k_var.head()\n",
    "k_var.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals:\n",
    "    # Want to convert blurb to count of words in blurb. (complete)\n",
    "    # Need to extract category name from category url. (complete)\n",
    "    # Need to convert launched_at time from Unix time to PST (complete)\n",
    "    # Need to convert goal amount to USD currency units (complete)\n",
    "    # Need to extract all states that are live from dataframe (complete)\n",
    "    # Need to calculate time to state change (state_change - launched_at) (complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating time to state change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "launch_date = []\n",
    "\n",
    "for date in k_var['launched_at']:\n",
    "    new_date = datetime.datetime.fromtimestamp(int(date)).strftime('%Y-%m-%d')\n",
    "    launch_date.append(new_date)\n",
    "launch_date = pd.to_datetime(launch_date)\n",
    "\n",
    "change_date = []\n",
    "for date in k_var['state_changed_at']:\n",
    "    new_date2 = datetime.datetime.fromtimestamp(int(date)).strftime('%Y-%m-%d')\n",
    "    change_date.append(new_date2)\n",
    "change_date = pd.to_datetime(change_date)\n",
    "\n",
    "#k_var['days_to_change'] = (pd.to_datetime(change_date['change_date']) - pd.to_datetime(launch_date['launch_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print k_var.dtypes\n",
    "k_var['launched_at'] = launch_date\n",
    "k_var['state_changed_at'] = change_date\n",
    "k_var['days_to_change'] = (k_var['state_changed_at'] - k_var['launched_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print k_var.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting goal amount to USD currency units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_var['goal_USD'] = k_var['goal'] * k_var['static_usd_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting catgory url to name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "category = ''\n",
    "for item in k_var['category']:\n",
    "    m = re.search('(?<=/categories/)\\w+', item)\n",
    "    #print m.group(0) \n",
    "    category += m.group(0) + ','\n",
    "# print category # containes multiple categories \n",
    "category_name = pd.DataFrame(category.split(','), columns = ['category'])\n",
    "\n",
    "k_var['category_name'] = category_name\n",
    "#k_var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print k_var.category_name.unique()\n",
    "print k_var.groupby('category_name').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# want to condense categories into bigger categories so that they have more of an effect\n",
    "# when used in the regression.\n",
    "\n",
    "# categories:\n",
    "#    art + crafts : 16254 + 2979\n",
    "#    design + fashion : 6733 + 8340\n",
    "#    journalism + publishing + comics : 2242 + 19305 + 3525\n",
    "#    food : 9765\n",
    "#    technology : 18007\n",
    "#    games : 11966\n",
    "#    theater + dance + music : 2880 + 1051 + 28130\n",
    "#    film + photography :  26512 + 19305\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#w['female'] = w['female'].map({'female': 1, 'male': 0})\n",
    "\n",
    "#test1['category_name'] = test1['category_name'].map({'art': 'art+craft', 'crafts':'art+craft',\n",
    "#                                                  'design': 'des + fash', 'fashion': 'des + fash'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_var.category_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_var.category_name.replace(['art', 'crafts', 'design', 'fashion','journalism', \\\n",
    "                            'publishing', 'comics', 'food', 'tech', 'games', \\\n",
    "                            'theater', 'dance', 'music', 'film', 'photography'], \\\n",
    "                           \n",
    "                           ['art+craft', 'art+craft','des+fash','des+fash',\\\n",
    "                            'jour+pub+com', 'jour+pub+com', 'jour+pub+com', \\\n",
    "                            'food', 'tech', 'games','theat+dan+mus', \\\n",
    "                            'theat+dan+mus', 'theat+dan+mus',\\\n",
    "                            'film+photo', 'film+photo'\n",
    "                           ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print k_var.category_name.unique()\n",
    "print k_var.groupby('category_name').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting blurb to count of words in blurb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blurb_count = []\n",
    "for blurb in k_var['blurb']:\n",
    "    #print blurb\n",
    "    try:\n",
    "        blurb_count.append(len(blurb.split(' ')))\n",
    "    except:\n",
    "        blurb_count.append(blurb)\n",
    "k_var['blurb_count'] = blurb_count\n",
    "k_var.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing states that are live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_var_state = k_var[k_var['state'] != 'live']\n",
    "print len(k_var)\n",
    "print len(k_var_state)\n",
    "k_var_state.groupby(['state']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaned kickstarter data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#kick_data = k_var_state.drop(['goal', 'static_usd_rate','currency','category'], axis=1)\n",
    "kick_data = k_var_state[['name','category_name','blurb','blurb_count','goal_USD','backers_count','launched_at','state_changed_at','days_to_change','state']]\n",
    "kick_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Get going by asking the following questions and looking for the answers with some code and plots:\n",
    "\n",
    "    Can you count something interesting?\n",
    "\n",
    "    Can you find some trends (high, low, increase, decrease, anomalies)?\n",
    "\n",
    "    Can you make a bar plot or a histogram?\n",
    "\n",
    "    Can you compare two related quantities?\n",
    "\n",
    "    Can you make a scatterplot?\n",
    "\n",
    "    Can you make a time-series plot?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Can you count something interesting? \n",
    "# Looking at number of successful, canceled, live and suspended projects and \n",
    "# relative numb of backers per year per state.\n",
    "\n",
    "g = kick_data[['backers_count','state']].groupby(['state', kick_data['launched_at'].dt.year,]).agg(['size','sum'])\n",
    "g.unstack('state').fillna(0)\n",
    "\n",
    "# Will have to divide sum (count of backers) by size (total number of projects) per year, per state \n",
    "# to get relative fraction of backers at that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Can you find some trends (high, low, increase, decrease, anomalies)?\n",
    "# Looking at number of projects launched per year and number of backers per year across all \n",
    "# states.\n",
    "\n",
    "g_size = kick_data[['backers_count']].groupby([kick_data['launched_at'].dt.year,]).agg(['size'])\n",
    "g_sum = kick_data[['backers_count']].groupby([kick_data['launched_at'].dt.year,]).agg(['sum'])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1)\n",
    "g_size.plot(ax=axes[0], kind= 'bar'); axes[0].set_title('total projects'); #plt.legend(loc='best')\n",
    "g_sum.plot(ax=axes[1], kind = 'bar'); axes[1].set_title('total backers'); #plt.legend(loc='best')\n",
    "\n",
    "\n",
    "# Conclusion: 1. There is not an equal number of projects or backers across years.\n",
    "#             2. Number of backers and number of projects logicaly seem to correlate\n",
    "#             3. As there are different number of projects launched per year, it is \n",
    "#                plausable that year has an effect on state of project and/or number of backers.\n",
    "#             SOLUTION: Choose projects from recent years (2014-2016)\n",
    "\n",
    "# Can you make a time-series plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Can you make a bar plot or a histogram?\n",
    "# number of project per state over all years: will use k_var bc kick_data does not have live data in it.\n",
    "# Conclustion: most projects, regardless of year, end up failing. \n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import cycle, islice\n",
    "\n",
    "my_colors = list(islice(cycle(['b', 'r', 'g', 'y','k']), None, len(k_var)))\n",
    "g = k_var.groupby(['state']).size()\n",
    "print g\n",
    "g.plot(kind='bar', stacked = True, color=my_colors)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Can you make a bar plot or a histogram?\n",
    "# divide count (of backers) by size (number of projects) to get average number of backers per year.\n",
    "%matplotlib inline\n",
    "k_success = k_var[k_var.state == 'successful']\n",
    "g = k_success[['backers_count','state']].groupby(['state', k_success['launched_at'].dt.year])\n",
    "agg = g.agg(['sum']).unstack('state')\n",
    "r = agg.reset_index()\n",
    "agg.plot(kind = 'bar')\n",
    "#agg.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of projects per state, per year: (kickstarter was launched, on April 28, 2009)\n",
    "\n",
    "# want to get percentage of backers per state per year...\n",
    "# (% will account for variation in # of projects per year, per state)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import cycle, islice\n",
    "\n",
    "my_colors = list(islice(cycle(['b', 'r', 'g']), None, len(k_var)))\n",
    "g = k_var[k_var.state != 'live'][k_var.state != 'suspended'].groupby([k_var['launched_at'].dt.year, 'state']).size()\n",
    "g = g.unstack().fillna(0)\n",
    "print g #raw counts\n",
    "g.plot(kind='bar', color=my_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seems like 2016 - 2014 is current\n",
    "# what may be driving this 2x increase in kickstarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of backers per year per state \n",
    "\n",
    "kick_data_state = kick_data[kick_data.state != 'suspended']#[kick_data_state['launched_at'].dt.year != 2016]\n",
    "g = kick_data_state[['backers_count','state','launched_at']].groupby(['state', kick_data_state['launched_at'].dt.year]).sum()\n",
    "g = g.unstack('state')\n",
    "print g\n",
    "g.plot(kind='bar')\n",
    "g.plot(kind='area')\n",
    "\n",
    "#kick_data_state.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kick_data_state.groupby([kick_data_state['launched_at'].dt.year]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Can you compare two related quantities? \n",
    "    # Does number of backers correlate with number of words in blurb? linear regression\n",
    "    # Does number of backers correlate with state? logistic regression\n",
    "\n",
    "# Can you make a scatterplot?\n",
    " \n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = kick_data[['blurb_count']]\n",
    "y = kick_data[['backers_count']]\n",
    "ax.set_title(\"blurb vs. backers\")\n",
    "ax.set_xlabel(\"blurb count\")\n",
    "ax.set_ylabel(\"backer count\")\n",
    "\n",
    "plt.plot(x, y, 'o', color='red')\n",
    "\n",
    "                            ####Look for outliers in blurb count and backers count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kick_corr = pd.DataFrame({'blurb count': kick_data['blurb_count'], \n",
    "                        'backer count': kick_data['backers_count']})\n",
    "kick_corr.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#kick_data_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing supspended and limiting dataset to recent years\n",
    "kick_data_state = kick_data_state[kick_data_state.state != 'canceled'][kick_data_state['launched_at'].dt.year >= 2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = kick_data_state[['backers_count','state']].groupby(['state']).count()\n",
    "my_colors = list(islice(cycle(['b', 'g', 'r']), None, len(kick_data_state[['state']])))\n",
    "g.plot(kind = 'bar', color = my_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Initialize label encoder\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# Convert State variable to numeric\n",
    "encoded_state = label_encoder.fit_transform(kick_data_state[\"state\"])\n",
    "print encoded_state\n",
    "print list(label_encoder.classes_)\n",
    "print list(label_encoder.inverse_transform([0,1]))\n",
    "\n",
    "# Initialize logistic regression model\n",
    "log_model = linear_model.LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "log_model.fit(y = pd.DataFrame(encoded_state), \n",
    "              X = pd.DataFrame(kick_data_state['backers_count']))\n",
    "\n",
    "# Check trained model intercept\n",
    "print log_model.intercept_\n",
    "\n",
    "# Check trained model coefficients\n",
    "print log_model.coef_\n",
    "\n",
    "kick_corr2 = pd.DataFrame({'state': encoded_state, \n",
    "                        'backer count': kick_data_state['backers_count']})\n",
    "kick_corr2.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print list(label_encoder.classes_)\n",
    "print list(label_encoder.inverse_transform([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print kick_data_state.columns\n",
    "print\" ____________________________________________\"\n",
    "print kick_data_state.category_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression: backers_count and state\n",
    "# http://patsy.readthedocs.io/en/latest/categorical-coding.html\n",
    "\n",
    "from patsy import dmatrices\n",
    "\n",
    "dta = kick_data_state\n",
    "\n",
    "encoded_state = label_encoder.fit_transform(kick_data_state[\"state\"])\n",
    "kick_data_state['encoded_state'] = encoded_state\n",
    "\n",
    "y, X = dmatrices('encoded_state ~ 0 + C(category_name) + blurb_count + backers_count + goal_USD', kick_data_state, return_type=\"dataframe\")\n",
    "print X.columns # have to -1 to get rid of intercept + so that art is not excluded\n",
    "\n",
    "#kick_data_state\n",
    "#print kick_data_state.columns\n",
    "#kick_data_state[(kick_data_state.encoded_state == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# column names for the dummy variables are ugly, so will rename those.\n",
    "\n",
    "# fix column names of X\n",
    "X = X.rename(columns = {'C(category_name)[art+craft]':'art+craft',\n",
    "                        'C(category_name)[des+fash]':'des+fash',\n",
    "                        'C(category_name)[film+photo]':'film+photo',\n",
    "                        'C(category_name)[food]':'food',\n",
    "                        'C(category_name)[games]':'games',\n",
    "                        'C(category_name)[jour+pub+com]':'jour+pub+com',\n",
    "                        'C(category_name)[technology]':'technology',\n",
    "                        'C(category_name)[theat+dan+mus]':'theat+dan+mus'\n",
    "                       })\n",
    "print X.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# column names for the dummy variables are ugly, so will rename those.\n",
    "\n",
    "# fix column names of X\n",
    "X = X.rename(columns = {'C(category_name)[art]':'art',\n",
    "                        'C(category_name)[comics]':'comics',\n",
    "                        'C(category_name)[crafts]':'crafts',\n",
    "                        'C(category_name)[dance]':'dance',\n",
    "                        'C(category_name)[design]':'design',\n",
    "                        'C(category_name)[fashion]':'fashion',\n",
    "                        'C(category_name)[film]':'film',\n",
    "                        'C(category_name)[food]':'food',\n",
    "                        'C(category_name)[games]':'games',\n",
    "                        'C(category_name)[journalism]':'journalism',\n",
    "                        'C(category_name)[music]':'music',\n",
    "                       'C(category_name)[photography]':'photography',\n",
    "                       'C(category_name)[publishing]':'publishing',\n",
    "                       'C(category_name)[technology]':'technology',\n",
    "                       'C(category_name)[theater]':'theater'\n",
    "                       })\n",
    "print X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flatten y into a 1-D array\n",
    "y = np.ravel(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate a logistic regression model, and fit with X and y\n",
    "model = LogisticRegression()\n",
    "model = model.fit(X, y)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "model.score(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what percentage are not state failed [0]? 40% are successful \n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine the coefficients\n",
    "coefficients = pd.DataFrame(zip(X.columns, np.transpose(model.coef_)))\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The higher the blurb_count and goal_USD the less likely for success\n",
    "# The higher the backer count, the more likely for success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Using a Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# So far, we have trained and tested on the same set. Let's instead split the data into a training set and a testing set.\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# evaluate the model by splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "model.score(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = model2.predict(X_test)\n",
    "print predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate class probabilities\n",
    "probs = model2.predict_proba(X_test)\n",
    "print probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# generate evaluation metrics\n",
    "print metrics.accuracy_score(y_test, predicted)\n",
    "#print metrics.roc_auc_score(y_test, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print metrics.confusion_matrix(y_test, predicted)\n",
    "print metrics.classification_report(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Using Cross-validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# evaluating the model using 10-fold cross-validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict the probability of an art project with 50 blurb count, 50 backers and a goal of 500 dollars.\n",
    "\n",
    "print list(label_encoder.inverse_transform([0,1]))\n",
    "model.predict_proba(np.array([0,0,1,0,0,0,0,0,10,200,500])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.predict_proba(np.array([0,0,0,0,0,0,0,0,50,50,500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                            #### How do we get categorical info into RFR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# making a dataframe with all features (called predictor_df)\n",
    "\n",
    "#predictor_ df = X\n",
    "predictor_df = kick_data_state[['backers_count', 'blurb_count', 'goal_USD']]\n",
    "predictors = list(predictor_df.columns.values)\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify the number of features\n",
    "numfeat = len(predictors)\n",
    "numfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the data into training/test sets...\n",
    "dataset = kick_data_state\n",
    "# test set:\n",
    "testing = dataset[0:len(dataset):5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here my y-value is a categorical variable (state)\n",
    "Y_test = testing.state  \n",
    "X_test = testing[predictors]\n",
    "\n",
    "# training set: everything not the test set is the training set\n",
    "#kick_data_state.index\n",
    "keep = testing.index # unique filter for specific row\n",
    "training = dataset[~dataset.index.isin(keep)]\n",
    "Y_train = training.state\n",
    "X_train = training[predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now use the optimal model's parameters to run random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "crf = RandomForestClassifier(n_estimators=1000, max_features=numfeat, max_depth=5) \n",
    "print(\"Parameters used in chosen RF model:\\n \" , crf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running Random Forest Regression\n",
    "\n",
    "crf.fit(X_train, Y_train)\n",
    "\n",
    "train_score = crf.score(X_train, Y_train)\n",
    "\n",
    "print('crf training score is: %f' %(train_score))\n",
    "\n",
    "test_score = crf.score(X_test, Y_test)\n",
    "\n",
    "print('crf test score is: %f' %(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test, Train, Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Version two\n",
    "# Use cross_validation.train_test_split, 2 times.\n",
    "\n",
    "y, x = dmatrices('encoded_state ~ backers_count', kick_data_state, return_type=\"dataframe\")\n",
    "\n",
    "# First with (70,30) => (training, validation_test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training, 30% test\n",
    "\n",
    "# Secondly use (50,50) -> (validation, test).\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5) # 15% test, 15% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2 = LogisticRegression()\n",
    "model2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = model2.predict(x_test)\n",
    "print predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate class probabilities\n",
    "probs = model2.predict_proba(x_test)\n",
    "print probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# generate evaluation metrics\n",
    "print metrics.accuracy_score(y_test, predicted)\n",
    "#print metrics.roc_auc_score(y_test, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print metrics.confusion_matrix(y_test, predicted)\n",
    "print metrics.classification_report(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are there repeates in data from sub-directories?? ...Yes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What is kick_data_state? ...\n",
    "# kick_data_state = kick_data_state[kick_data_state.state != 'canceled'][kick_data_state['launched_at'].dt.year >= 2014]\n",
    "\n",
    "kick_data_state.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#g = kick_data_state.groupby(['blurb'])\n",
    "#size = g.size()\n",
    "#size[size > 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# people can resubmit their projects a 2nd, 3rd etc. time... i.e. there are repeates.\n",
    "# Therefore, for this dataset we should only analyze the 1st submission (launched at the most recent date).\n",
    "\n",
    "# This table has projects that have been submitted multiple times:\n",
    "g_kick_data = kick_data_state.groupby(['blurb'])\n",
    "g_filtered = g_kick_data.filter(lambda x: len(x) > 1).sort_values(['blurb','launched_at'])\n",
    "len(g_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in g_filtered.iterrows():\n",
    "    print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(kick_data_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This table has projects that have only been submitted once:\n",
    "g2_filtered = g_kick_data.filter(lambda x: len(x) <= 1).sort_values(['blurb','launched_at'])\n",
    "len(g2_filtered)\n",
    "\n",
    "# 95978 + 1012 = 96990"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing accuracy of \"live\" data predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine 07-15 live rows into one csv. \n",
    "# Join '07-15 live' table w/ most resent data table (09/15 data).\n",
    "# Find overlap of live and new rows based on same launched_at date and same blurb description\n",
    "# select rows that have switched from live to failed/successful\n",
    "# add identified rows to new csv file\n",
    "# Predict state change on this dataset and compare to actual results to get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What is k_var? Entire cleaned dataset with all outcomes\n",
    "\n",
    "live_df = k_var[k_var.state == 'live']\n",
    "live_df.to_csv('/Users/auroraleport/Documents/LePort_git/07_15_live.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kd915 = pd.read_csv('/Users/auroraleport/Documents/LePort_git/9_15_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This table has projects that have only been submitted once and are successes or failures:\n",
    "g_kd915 = kd915[(kd915.state != 'live') & (kd915.state != 'suspended') & (kd915.state != 'canceled')].groupby(['blurb'])\n",
    "kd915_filtered = g_kd915.filter(lambda x: len(x) <= 1).sort_values(['blurb','launched_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kd915_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# are there live datasets that have multiple submissions?\n",
    "g_live_df = live_df.groupby(['blurb'])\n",
    "live_df_filtered = g_live_df.filter(lambda x: len(x) <= 1).sort_values(['blurb','launched_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# b4 taking out live from kd915\n",
    "# print len(live_df_filtered) # there are no multiple submissions for live datasets\n",
    "# print len(live_df)\n",
    "# print len(kd915_filtered)\n",
    "# print len(kd915)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# after taking out live from kd915\n",
    "print len(live_df_filtered) # there are no multiple submissions for live datasets\n",
    "print len(live_df)\n",
    "print len(kd915_filtered)\n",
    "print len(kd915)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combining tables to look for overlaps\n",
    "live_kd915_filt_df = pd.concat([live_df, kd915_filtered], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_live_kd915_filt_df = live_kd915_filt_df.groupby(['blurb'])\n",
    "live_woutcome = g_live_kd915_filt_df.filter(lambda x: len(x) > 1).sort_values(['blurb','launched_at'])\n",
    "live_woutcome[['name','category_name','blurb','blurb_count','goal_USD','backers_count','launched_at',\\\n",
    "               'state_changed_at','days_to_change','state']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfiltered 09 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kd915 is the full dataset, containing projects that have been submitted multiple times and \n",
    "# have live, successful, failed, suspended projects.\n",
    "# Combining tables to look for overlaps\n",
    "\n",
    "live_kd915_df = pd.concat([live_df, kd915], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_live_kd915_df = live_kd915_df.groupby(['blurb'])\n",
    "live_woutcome_unfilt = g_live_kd915_df.filter(lambda x: len(x) > 1).sort_values(['blurb','launched_at'])\n",
    "live_woutcome_unfilt[['name','category_name','blurb','blurb_count','goal_USD','backers_count','launched_at',\\\n",
    "               'state_changed_at','days_to_change','state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# want to run live rows that have an outcome in 9_15 dataset through the algorithem to see if it predicts the\n",
    "# correct outcome\n",
    "# filtering for lives rows:\n",
    "\n",
    "liveonly_live_woc = live_woutcome[live_woutcome.state == 'live']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(liveonly_live_woc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filtering for live projects that have been submitted multiple times.\n",
    "\n",
    "notlive_live_woc = live_woutcome[(live_woutcome['state'] == 'failed') | (live_woutcome['state'] == 'successful')]\n",
    "notlive_live_woc = notlive_live_woc[['name','category_name','blurb','blurb_count','goal_USD','backers_count',\\\n",
    "                               'launched_at','state_changed_at','days_to_change','state']]\n",
    "print len(notlive_live_woc)\n",
    "notlive_live_woc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liveonly_live_woc = liveonly_live_woc[['name','category_name','blurb','blurb_count','goal_USD','backers_count',\\\n",
    "                               'launched_at','state_changed_at','days_to_change','state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "liveonly_live_woc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converting category_name in live dataset to numerical values.\n",
    "from patsy import dmatrices\n",
    "\n",
    "encoded_state2 = label_encoder.fit_transform(liveonly_live_woc['state'])\n",
    "liveonly_live_woc['encoded_state'] = encoded_state2\n",
    "\n",
    "y_live, X_live = dmatrices('encoded_state2 ~ 0 + C(category_name) + blurb_count + backers_count + goal_USD', \\\n",
    "                           liveonly_live_woc, return_type='dataframe')\n",
    "\n",
    "print X_live.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# column names for the dummy variables are ugly, so will rename those.\n",
    "\n",
    "# fixing column names: \n",
    "X_live = X_live.rename(columns = {'C(category_name)[art+craft]':'art+craft',\n",
    "                        'C(category_name)[des+fash]':'des+fash',\n",
    "                        'C(category_name)[film+photo]':'film+photo',\n",
    "                        'C(category_name)[food]':'food',\n",
    "                        'C(category_name)[games]':'games',\n",
    "                        'C(category_name)[jour+pub+com]':'jour+pub+com',\n",
    "                        'C(category_name)[technology]':'technology',\n",
    "                        'C(category_name)[theat+dan+mus]':'theat+dan+mus',\n",
    "                       })\n",
    "print X_live.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_live.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_live = model.predict(X_live)\n",
    "predicted_live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_live)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Want to get a list of the live outcomes so that we can get accuracy of prediction\n",
    "from sklearn import metrics\n",
    "\n",
    "# generate evaluation metrics\n",
    "y_outcomes = notlive_live_woc\n",
    "y_outcomes_le = label_encoder.fit_transform(y_outcomes['state'])\n",
    "print y_outcomes_le\n",
    "print list(label_encoder.classes_)\n",
    "print list(label_encoder.inverse_transform([0,1]))\n",
    "print metrics.accuracy_score(y_outcomes_le, predicted_live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print list(label_encoder.inverse_transform([0,1]))\n",
    "# blurb_count = 21, backer_count = 0, goal_USD = 1100\n",
    "model.predict_proba(np.array([0,0,1,0,0,0,0,0,30,50,1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_var.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# based on trajectory of first week can we predict final backer count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#7_15_live = k_var[k_var.state == 'live']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#k_var.to_csv('9_15_full', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
